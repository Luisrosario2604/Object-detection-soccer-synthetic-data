{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-2sJ39LTqMO"
   },
   "source": [
    "# YoloV8 - Object detection - Blender soccer synthetic images\n",
    "\n",
    "*   yolov8 github : https://github.com/ultralytics/ultralytics\n",
    "*   yolov8 docs : https://ultralytics.com/yolov8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr7LVVqpUqBo"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Check [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) of Yolo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need the last version of [torch](https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install torch if needed (check oldest version in torch website)\n",
    "\n",
    "# Last version at this moment\n",
    "\n",
    "# With pip3 :\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "\n",
    "# With conda :\n",
    "#!conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to install tqdm and ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ds9Oc6leVaZc",
    "outputId": "03075a6b-a13e-4b55-8fd3-ed2e194d5812"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.54  Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Setup complete  (8 CPUs, 15.9 GB RAM, 101.8/118.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "## install tqdm\n",
    "\n",
    "!pip install tqdm --upgrade\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "## install ultralytics\n",
    "\n",
    "!pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If all is already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.54  Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Setup complete  (8 CPUs, 15.9 GB RAM, 100.0/118.0 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check python version and if you use GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your python version, you will need more than Python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.16 (main, Mar  8 2023, 10:39:24) [MSC v.1916 64 bit (AMD64)]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if you are using your GPU (not required), you can train with a CPU but it's slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1050 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports are always needed\n",
    "import torch\n",
    "\n",
    "# get index of currently selected device\n",
    "torch.cuda.current_device() # returns 0 in my case\n",
    "\n",
    "\n",
    "# get number of GPUs available\n",
    "torch.cuda.device_count() # returns 1 in my case\n",
    "\n",
    "\n",
    "# get the name of the device\n",
    "torch.cuda.get_device_name(0) # good old Tesla K80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yt1WtiuxieK"
   },
   "source": [
    "# Imports / Globals\n",
    "\n",
    "All imports and global variables (you will need to change the paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I8hhKBYIVKon"
   },
   "outputs": [],
   "source": [
    "## importing required libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yolo structure :\n",
    "\n",
    "```\n",
    ".\n",
    "└── data\n",
    "    ├── all_annot\n",
    "    ├── all_imgs\n",
    "    └── yolo_training_dataset\n",
    "        ├── images          # Name and struture required\n",
    "        │    ├── test       # Name and struture required\n",
    "        │    ├── train      # Name and struture required\n",
    "        │    └── val        # Name and struture required\n",
    "        └── labels          # Name and struture required\n",
    "            ├── train       # Name and struture required\n",
    "            └── val         # Name and struture required\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linux / Mac (replace all path by yours). Please respect the Yolo structure for the data storage or the training step will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir          = \"./data/\" # Change to your working directory\n",
    "path_imgs         = root_dir + \"all_imgs/\" # Put all your images here\n",
    "path_labels       = root_dir + \"all_annot/\" # Put all your annotations here\n",
    "path_train_imgs   = root_dir + \"yolo_training_dataset/images/train/\" # Create the directory or change path\n",
    "path_train_labels = root_dir + \"yolo_training_dataset/labels/train/\" # Create the directory or change path\n",
    "path_val_imgs     = root_dir + \"yolo_training_dataset/images/val/\" # Create the directory or change path\n",
    "path_val_labels   = root_dir + \"yolo_training_dataset/labels/val/\" # Create the directory or change path\n",
    "path_test_imgs    = root_dir + \"yolo_training_dataset/images/test/\" # Create the directory or change path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Windows (replace all path by yours). Please respect the Yolo structure for the data storage or the training step will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir          = \"./data/\" # Change to your working directory\n",
    "path_imgs         = root_dir + \"all_imgs\\\\\" # Put all your images here\n",
    "path_labels       = root_dir + \"all_annot\\\\\" # Put all your annotations here\n",
    "path_train_imgs   = root_dir + \"yolo_training_dataset\\\\images\\\\train\\\\\" # Create the directory or change path\n",
    "path_train_labels = root_dir + \"yolo_training_dataset\\\\labels\\\\train\\\\\" # Create the directory or change path\n",
    "path_val_imgs     = root_dir + \"yolo_training_dataset\\\\images\\\\val\\\\\" # Create the directory or change path\n",
    "path_val_labels   = root_dir + \"yolo_training_dataset\\\\labels\\\\val\\\\\" # Create the directory or change path\n",
    "path_test_imgs    = root_dir + \"yolo_training_dataset\\\\images\\\\test\\\\\" # Create the directory or change path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP8yFZBKxNop"
   },
   "source": [
    "# Remove\n",
    "\n",
    "Remove all files in ```train``` / ```validation``` and ```test``` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zMtA1dKtuDdc"
   },
   "outputs": [],
   "source": [
    "def remove_files_dir(dir):\n",
    "  for filename in os.listdir(dir):\n",
    "    file_path = os.path.join(dir, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "def remove_all_files():\n",
    "  remove_files_dir(path_train_imgs)\n",
    "  remove_files_dir(path_train_labels)\n",
    "  remove_files_dir(path_val_imgs)\n",
    "  remove_files_dir(path_val_labels)\n",
    "  remove_files_dir(path_test_imgs)\n",
    "\n",
    "  print(\"--- Done ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ytf5OisJCTQ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Done ---\n"
     ]
    }
   ],
   "source": [
    "remove_all_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1KbzWRGxvzX"
   },
   "source": [
    "# Split\n",
    "\n",
    "Split all the dataset to train validation and tests (from ```path_imgs``` and ```path_labels``` paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c3QatSoyJF_",
    "outputId": "49adee74-3305-4618-cac2-32669e2b1abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Total imgs : total:1000 train:720 validation:180 test:100 ---\n",
      " --- Total is ok ---\n",
      "--- Done ---\n"
     ]
    }
   ],
   "source": [
    "def split_data(split_val=0.2, split_test=0.1):\n",
    "  imgs_list = list(set([name[:-4] for name in os.listdir(path_imgs)]))\n",
    "\n",
    "  imgs_nb_total   = len(imgs_list)\n",
    "  imgs_nb_test    = int(imgs_nb_total * split_test)\n",
    "  imgs_nb_train   = int(imgs_nb_total - imgs_nb_test)\n",
    "  imgs_nb_val     = int(imgs_nb_train * split_val)\n",
    "  imgs_nb_train   = int(imgs_nb_train - imgs_nb_val)\n",
    "\n",
    "\n",
    "  print(f\" --- Total imgs : total:{imgs_nb_total} train:{imgs_nb_train} validation:{imgs_nb_val} test:{imgs_nb_test} ---\")\n",
    "  \n",
    "  if imgs_nb_test + imgs_nb_train + imgs_nb_val == imgs_nb_total:\n",
    "    print(f\" --- Total is ok ---\")\n",
    "  else:\n",
    "    print(f\" --- Total is not ok ---\")\n",
    "\n",
    "  #random.seed(42)\n",
    "  random.shuffle(imgs_list)\n",
    "\n",
    "  for img in imgs_list[:imgs_nb_train]:\n",
    "    shutil.copy2(path_imgs + img + \".png\", path_train_imgs + img + \".png\")\n",
    "    shutil.copy2(path_labels + img + \".txt\", path_train_labels + img + \".txt\")\n",
    "\n",
    "  for img in imgs_list[imgs_nb_train:imgs_nb_train + imgs_nb_val]:\n",
    "    shutil.copy2(path_imgs + img + \".png\", path_val_imgs + img + \".png\")\n",
    "    shutil.copy2(path_labels + img + \".txt\", path_val_labels + img + \".txt\")\n",
    "\n",
    "  for img in imgs_list[imgs_nb_train + imgs_nb_val:imgs_nb_total]:\n",
    "    shutil.copy2(path_imgs + img + \".png\", path_test_imgs + img + \".png\")\n",
    "\n",
    "  print(\"--- Done ---\")\n",
    "\n",
    "\n",
    "split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZbwT0KTB-9-"
   },
   "source": [
    "# Change labels\n",
    "\n",
    "Change labels without copying images (if you want to change the classes but you don't want to split again the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OFNRprSKB_Hn"
   },
   "outputs": [],
   "source": [
    "remove_files_dir(path_train_labels)\n",
    "remove_files_dir(path_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ssOkF8JPCcJ1",
    "outputId": "77d6b6a4-d03f-4ed1-c1ab-d0527ee4a4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Done ---\n"
     ]
    }
   ],
   "source": [
    "def copy_labels():\n",
    "  imgs_list_train = list(set([name[:-4] for name in os.listdir(path_train_imgs)]))\n",
    "  imgs_list_val = list(set([name[:-4] for name in os.listdir(path_val_imgs)]))\n",
    "\n",
    "  for img in imgs_list_train:\n",
    "    shutil.copy2(path_labels + img + \".txt\", path_train_labels + img + \".txt\")\n",
    "\n",
    "  for img in imgs_list_val:\n",
    "    shutil.copy2(path_labels + img + \".txt\", path_val_labels + img + \".txt\")\n",
    "\n",
    "  print(\"--- Done ---\")\n",
    "\n",
    "\n",
    "copy_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY2755x7CHmr"
   },
   "source": [
    "# Use a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"Path_to_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to modify ```config.yaml```, for more information check YoloV8 documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3rg0Xe7l_gd",
    "outputId": "912bc403-3b7a-4923-b6a8-4a8e4ec28bfd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.59 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.54  Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=./config_low.yaml, epochs=20, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=1, project=./training_result, name=special_val_real_small, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=training_result\\special_val_real_small\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2118370  ultralytics.nn.modules.Detect                [6, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11137922 parameters, 11137906 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "WARNING  NMS time limit 0.550s exceeded\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\leuvi\\OneDrive\\Bureau\\Tfm\\Training\\yolo_training_dataset\\labels\\train... 720 images, 1 backgrounds, 0 corrupt: 100%|██████████| 720/720 [00:01<00:00, 534.55i\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\leuvi\\OneDrive\\Bureau\\Tfm\\Training\\yolo_training_dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\leuvi\\OneDrive\\Bureau\\Tfm\\Training\\yolo_training_dataset\\labels\\val... 180 images, 0 backgrounds, 0 corrupt: 100%|██████████| 180/180 [00:00<00:00, 549.61it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\leuvi\\OneDrive\\Bureau\\Tfm\\Training\\yolo_training_dataset\\labels\\val.cache\n",
      "Plotting labels to training_result\\special_val_real_small\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 1 dataloader workers\n",
      "Logging results to \u001b[1mtraining_result\\special_val_real_small\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20      2.26G      1.212      1.681     0.8828        142        640: 100%|██████████| 90/90 [01:08<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:12<00:00,  1.02s/it]\n",
      "                   all        180       2238       0.69      0.624      0.677      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20      2.27G      1.185     0.8432      0.856        182        640: 100%|██████████| 90/90 [01:10<00:00,  1.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                   all        180       2238       0.85      0.805      0.856      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20      2.27G       1.25     0.8653     0.8673        142        640: 100%|██████████| 90/90 [01:13<00:00,  1.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.03it/s]\n",
      "                   all        180       2238       0.84       0.78      0.821      0.471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20      2.27G      1.215     0.8363     0.8729        198        640: 100%|██████████| 90/90 [01:16<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.03it/s]\n",
      "                   all        180       2238      0.873      0.792      0.842      0.512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20      2.27G      1.232     0.7306     0.8722        206        640: 100%|██████████| 90/90 [01:17<00:00,  1.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                   all        180       2238      0.876      0.816      0.889       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20      2.27G      1.134     0.6708     0.8589        167        640: 100%|██████████| 90/90 [01:19<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                   all        180       2238      0.884      0.849      0.908      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20      2.27G      1.049     0.6034      0.845        182        640: 100%|██████████| 90/90 [01:21<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                   all        180       2238      0.946      0.887      0.914      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20      2.27G      0.976     0.5497     0.8392        197        640: 100%|██████████| 90/90 [01:22<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.06it/s]\n",
      "                   all        180       2238      0.926      0.867      0.933      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20      2.27G     0.9305     0.5287     0.8359        148        640: 100%|██████████| 90/90 [01:23<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.00it/s]\n",
      "                   all        180       2238       0.98      0.883      0.939      0.663\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20      2.27G     0.8889     0.4937     0.8288        159        640: 100%|██████████| 90/90 [01:23<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.03it/s]\n",
      "                   all        180       2238      0.958      0.888      0.939       0.68\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20      2.27G     0.8107     0.4691     0.8228         93        640: 100%|██████████| 90/90 [01:22<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                   all        180       2238      0.969      0.868      0.939      0.682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20      2.27G     0.7596     0.4516     0.8163        101        640: 100%|██████████| 90/90 [01:20<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.01it/s]\n",
      "                   all        180       2238      0.978      0.882      0.939      0.702\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20      2.27G     0.7147     0.4278     0.8119        101        640: 100%|██████████| 90/90 [01:21<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.03it/s]\n",
      "                   all        180       2238      0.965      0.879      0.942      0.689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20      2.27G     0.6871      0.422     0.8052         69        640: 100%|██████████| 90/90 [01:21<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                   all        180       2238      0.983      0.883      0.947      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20      2.27G     0.6618     0.4024      0.808         94        640: 100%|██████████| 90/90 [01:21<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                   all        180       2238       0.96      0.887      0.949      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20      2.27G     0.6298     0.3871     0.8018        101        640: 100%|██████████| 90/90 [01:20<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.02it/s]\n",
      "                   all        180       2238       0.98      0.882      0.948      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20      2.27G     0.6169     0.3799     0.8021        104        640: 100%|██████████| 90/90 [01:20<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.05it/s]\n",
      "                   all        180       2238      0.974      0.887      0.951      0.743\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20      2.27G      0.596     0.3686     0.7989         81        640: 100%|██████████| 90/90 [01:20<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                   all        180       2238      0.975      0.892      0.952      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20      2.27G     0.5725      0.354     0.7965         90        640: 100%|██████████| 90/90 [01:20<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n",
      "                   all        180       2238       0.98      0.883      0.952      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20      2.27G     0.5559      0.341     0.7947         78        640: 100%|██████████| 90/90 [01:21<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:13<00:00,  1.09s/it]\n",
      "                   all        180       2238      0.983      0.891       0.95      0.769\n",
      "\n",
      "20 epochs completed in 0.550 hours.\n",
      "Optimizer stripped from training_result\\special_val_real_small\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from training_result\\special_val_real_small\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating training_result\\special_val_real_small\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.54  Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:12<00:00,  1.06s/it]\n",
      "                   all        180       2238      0.983      0.891       0.95      0.769\n",
      "                  ball        180        177          1      0.425      0.767      0.455\n",
      "               referee        180        134      0.993      0.999      0.995      0.895\n",
      "             goal_real        180         38      0.977          1      0.995      0.727\n",
      "              goal_val        180         33      0.986       0.97      0.969      0.767\n",
      "            player_val        180        915      0.971      0.972      0.986      0.881\n",
      "           player_real        180        941      0.974       0.98       0.99      0.889\n",
      "Speed: 0.4ms preprocess, 13.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mtraining_result\\special_val_real_small\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8s.pt\")\n",
    "\n",
    "# Use the model\n",
    "# Use config_low_linux_mac.yaml or config_low_windows.yaml depending on your OS, don't forget to change paths on the yaml\n",
    "model.train(data=root_dir + \"config_low_linux_mac.yaml\", epochs=20, imgsz=640, save=True, project=root_dir + (\"training_result\") , name=\"Model_nb_1\", batch=8, workers=1)  # train the model\n",
    "# model.train(data=root_dir + \"config_4c.yaml\", epochs=15, imgsz=640, save=True, project=root_dir + (\"training_result\") , name=\"15epochs_4classes_smallModel\", batch=8, workers=1, conf=0.2, save_conf=True, max_det=25, save_json=True, plots=True)  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2s0SXl1DKnUA",
    "outputId": "311c1b2c-5f8f-4411-fe6e-6d4f71ea0232"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.54  Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\leuvi\\OneDrive\\Bureau\\Tfm\\Training\\yolo_training_dataset\\labels\\val.cache... 180 images, 0 backgrounds, 0 corrupt: 100%|██████████| 180/180 [00:00<?, ?it/s]\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [00:13<00:00,  1.70it/s]\n",
      "                   all        180       2238      0.983      0.891      0.951      0.777\n",
      "                  ball        180        177      0.997      0.424      0.767      0.474\n",
      "               referee        180        134      0.993      0.999      0.995      0.903\n",
      "             goal_real        180         38      0.977          1      0.995      0.728\n",
      "              goal_val        180         33      0.988       0.97      0.969       0.77\n",
      "            player_val        180        915      0.972      0.972      0.986      0.887\n",
      "           player_real        180        941      0.974       0.98      0.993      0.898\n",
      "Speed: 0.7ms preprocess, 19.4ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mtraining_result\\special_val_real_small2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4oiELDm7Us-",
    "outputId": "4daf0696-3afe-4f64-8567-e4b95dbeb0c1"
   },
   "outputs": [],
   "source": [
    "results = model(root_dir + \".png\", save=True)# predict on an image (change path of the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvNOfZ4F7Uzy",
    "outputId": "3bcbc35c-98b3-4028-9ee0-73de99e6b384"
   },
   "outputs": [],
   "source": [
    "success = model.export()  # export the model to ONNX format"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
